{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 03 **Computaion of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few distinct differences between Tensorflow and Pytorch when it comes to data compuation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|               | TensorFlow      | PyTorch        |\n",
    "|---------------|-----------------|----------------|\n",
    "| Framework     | Define-and-run  | Define-by-run  |\n",
    "| Graph         | Static | Dynamic|\n",
    "| Debug         | Non-native debugger (tfdbg) |pdb(ipdb) Python debugger|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How \"Graph\" is defined in each framework?**\n",
    "\n",
    "**TensorFlow:** \n",
    "\n",
    "- Static graph.\n",
    "\n",
    "- Once define a computational graph and excute the same graph repeatedly.\n",
    "\n",
    "- Pros: \n",
    "\n",
    "    (1) Optimizes the graph upfront and makes better distributed computation.\n",
    "    \n",
    "    (2) Repeated computation does not cause additional computational cost.\n",
    "\n",
    "\n",
    "- Cons: \n",
    "\n",
    "    (1) Difficult to perform different computation for each data point.\n",
    "    \n",
    "    (2) The structure becomes more complicated and harder to debug than dynamic graph. \n",
    "\n",
    "**PyTorch:** \n",
    "\n",
    "- Dynamic graph.\n",
    "\n",
    "- Does not define a graph in advance. Every forward pass makes a new computational graph.\n",
    "\n",
    "- Pros: \n",
    "\n",
    "    (1) Debugging is easier than static graph.\n",
    "    \n",
    "    (2) Keep the whole structure concise and intuitive. \n",
    "    \n",
    "    (3) For each data point and time different computation can be performed.\n",
    "    \n",
    "    \n",
    "- Cons: \n",
    "\n",
    "    (1) Repetitive computation can lead to slower computation speed. \n",
    "    \n",
    "    (2) Difficult to distribute the work load in the beginning of training.\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dynamic and Static Graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[TensorFlow]** Graph and session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.Graph: \n",
    "\n",
    "What is tf.Graph?\n",
    "\n",
    "* tf.Graph should be defined before add operations and tensors, otherwise we use default graph.\n",
    "\n",
    "* tf.Graph is needed whenever there are multiple models in one file.\n",
    "\n",
    "* tf.Graph contains two informations. \n",
    "  \n",
    "    (1) **Graph Structure**: Nodes(Operations) and Edges(Tensors) of the graph.\n",
    "  \n",
    "    (2) **Graph Collections**: Store all the collections of metadata. Use tf.add_to_collection and tf.get_collection to access thses collections. \n",
    "    \n",
    "    \n",
    "* If we do not specify tf.Graph, TF automatically defines default graph which we cannot see in the code.\n",
    "\n",
    "* Node: **tf.Operation** - Edge: **tf.Tensor**\n",
    "\n",
    "* Each and every tf.Operation and tf.Tensor is added to tf.Graph instacne. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example 1)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_graph = tf.Graph()\n",
    "with tf_graph.as_default():\n",
    "    x = tf.constant([1, 2], shape = [1,2])\n",
    "    y = tf.constant([3, 4], shape = [2,1])\n",
    "    z = tf.matmul(x, y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example:\n",
    "    - tf.constant() is a tf.Operation that creates 42.0, adds it to a tf.Graph and returns a tf.Tensor.\n",
    "    - tf.matmul() is a tf.Operation that calculates multiplication of x and y, adds it to a tf.Graph and returns a Tensor.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.Session: \n",
    "\n",
    "What is tf.Session?\n",
    "\n",
    "* tf.Session incorporates operations and tensors. tf.Session also excute and evaluate the operations and tensors.\n",
    "\n",
    "* tf.Session takes three arguments, which are all optional\n",
    "  \n",
    "    (1) **target**: The excution engine to connect to.\n",
    "        \n",
    "    (2) **graph**: tf.Graph that session wants to launch. If not specified, automatically links default graph.\n",
    "    \n",
    "    (3) **config**: A ConfigProto protocol buffer with configuration options. \n",
    "    \n",
    "    \n",
    "* Unlike tf.Graph, tf.Session should be placed before the operations. \n",
    "\n",
    "* tf.Session.run() function excutes the given operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example 2)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=tf_graph) as sess:\n",
    "  initialize = tf.global_variables_initializer()\n",
    "  sess.run(initialize)\n",
    "  print(sess.run(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, Example 2 can be excuted without specifying a graph instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example 3)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11]]\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.constant([1, 2], shape = [1,2])\n",
    "y1 = tf.constant([3, 4], shape = [2,1])\n",
    "z1 = tf.matmul(x1, y1)\n",
    "with tf.Session() as sess:\n",
    "  initialize = tf.global_variables_initializer()\n",
    "  sess.run(initialize)\n",
    "  print(sess.run(z1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.InteractiveSession: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow supports tf.InteractiveSession() that enables more convenient form of session. \n",
    "\n",
    "Use tf.Tensor.eval() to obtain the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x2 = tf.constant([1, 2], shape = [1,2])\n",
    "y2 = tf.constant([3, 4], shape = [2,1])\n",
    "z2 = tf.matmul(x2, y2)\n",
    "print(z2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[PyTorch]** Dynamic Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike TensorFlow, PyTorch does not require graph instance or session instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example 4)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.from_numpy(np.asarray([[1,2]]))\n",
    "b = torch.from_numpy(np.asarray([[3,4]]).T)\n",
    "c = torch.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no graph instance and session instance, the code is much simpler for the same operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation can be also computed with torch.autograd.Variable. With torch.autograd.Variable, we can compute gradients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 11\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a1 = Variable(torch.from_numpy(np.asarray([[1,2]])), requires_grad=True)\n",
    "b1 = Variable(torch.from_numpy(np.asarray([[3,4]]).T), requires_grad=True)\n",
    "c1 = torch.matmul(a1, b1)\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the gradient as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 15  20\n",
      "[torch.LongTensor of size 1x2]\n",
      " Variable containing:\n",
      "  5\n",
      " 10\n",
      "[torch.LongTensor of size 2x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c1.backward(retain_graph=True)\n",
    "print(a1.grad, b1.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
